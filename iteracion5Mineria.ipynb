{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58018c08-879c-406e-9dfb-587d2e2af2f0",
     "showTitle": false,
     "title": ""
    },
    "id": "CKmpCIsGv2-F"
   },
   "source": [
    "Miscelaneo\n",
    "http://www.bom.gov.au/\n",
    "\n",
    "https://www.portalminero.com/pages/viewpage.action?pageId=6661853\n",
    "\n",
    "https://datos.bancomundial.org/indicator/NY.GDP.MINR.RT.ZS?locations=AU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bcd0a0c-6ff1-490a-9db5-605424625cfc",
     "showTitle": false,
     "title": ""
    },
    "id": "jA-IO-ykUfME"
   },
   "source": [
    "# Informe t칠cnico tercera evaluaci칩n Mineria de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e732f167-f311-40e8-97da-ce918c290230",
     "showTitle": false,
     "title": ""
    },
    "id": "I2UBV6ejWc-P"
   },
   "source": [
    "Integrantes:\n",
    "\n",
    "*   Felipe Salas\n",
    "*   Brian Urbina\n",
    "*   Marcelo Montecino\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69b6bf30-0625-464d-92b2-5d8bcc7697eb",
     "showTitle": false,
     "title": ""
    },
    "id": "dUDW-HhuvyEQ"
   },
   "source": [
    "1. Datos a trabajar\n",
    "\n",
    "\n",
    "      *   2009-2015 游듚n",
    "      *   Se comparan resultados con 2016\n",
    "      *   No se toman los a침os 2007, 2008, 2017,2018 游듚n",
    "\n",
    " 2. Del caso de negocio asociado al hallazgo, debe considerar 2 variables de target (Categ칩rica y Continua)\n",
    "\n",
    " 3. Para cada una de las variables seleccionadas**\n",
    "\n",
    "\n",
    "      *   Imputar los datos necesarios con 3 t칠cnicas distintas y presentar las matrices de correlaci칩n de c/u de ellas\n",
    "      *   Argumentar cual de esas imputaciones es la seleccionada\n",
    "\n",
    "HASTA AQUI ES EL AVANCE DEL Domingo 9\n",
    "<HR>\n",
    "  4. Generar 3 modelos para c/u de las variables y comparar los scoring\n",
    "  5. Seleccionar el modelo ganador\n",
    "  6. Se definir치 como criterio de 칠xito de la siguiente forma\n",
    "\n",
    "      *  Predicci칩n para 7 dias, debe al menos 5 d칤as tener un margen de error de un 8% (mas o menos)\n",
    "  7. Comparaci칩n con los datos del a침o 2016\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba886381-b055-4feb-a711-451450674248",
     "showTitle": false,
     "title": ""
    },
    "id": "9dauBcV0wVay"
   },
   "source": [
    "\n",
    "\n",
    "JUPYTER PARA ENTREGA 3\n",
    "\n",
    "WORD CON\n",
    "INFORME CON ENTREGA 1, 2 Y 3\n",
    "INTRODUCCION, INDICE, CONCLUSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04036e8-157a-458a-982a-8c23142d8ac3",
     "showTitle": false,
     "title": ""
    },
    "id": "cUURKy6YySLg"
   },
   "source": [
    "## 1.- Comprensi칩n del negocio.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc1aad0-96a6-4745-bead-a9c19cb67771",
     "showTitle": false,
     "title": ""
    },
    "id": "NRJ8U5sfpZLs"
   },
   "source": [
    "1. **Contexto General de Australia**\n",
    "\n",
    "Australia es un pa칤s vasto con una superficie de aproximadamente 7.741.220 km, lo que lo convierte en el sexto pa칤s m치s grande del mundo. La poblaci칩n se concentra mayoritariamente en las zonas urbanas, especialmente en las ciudades de S칤dney, Melbourne, Brisbane, Perth y Adelaide. El pa칤s est치 dividido en seis estados (New South Wales, Victoria, Queensland, South Australia, Western Australia y Tasmania) y dos territorios (Northern Territory y Australian Capital Territory).\n",
    "\n",
    "2. **Clima y Geograf칤a**\n",
    "\n",
    "Australia es el continente m치s seco despu칠s de la Ant치rtida, con un clima predominantemente des칠rtico y semi치rido, aunque hay variaciones clim치ticas significativas:\n",
    "- **Norte:** Clima tropical con una estaci칩n seca en invierno y una h칰meda en verano.\n",
    "- **Sureste y Sudoeste:** Clima templado con cuatro estaciones.\n",
    "- **Centro:** Predomina el clima des칠rtico.\n",
    "- **Gran Cordillera Divisoria:** Extensa cadena monta침osa que influye en los patrones de precipitaci칩n y alberga los r칤os m치s caudalosos del pa칤s, como el Murray y el Darling.\n",
    "\n",
    "3. **Sector Minero en Australia**\n",
    "\n",
    "El sector minero es uno de los pilares econ칩micos de Australia, representando alrededor del 10% del PIB con un valor aproximado de 148.000 millones de AUD. Australia es uno de los principales productores y exportadores de minerales y productos energ칠ticos a nivel mundial. Los productos mineros m치s significativos incluyen Mineral de Hierro, Carb칩n, Bauxita, Al칰mina, Zinc y Gas Natural Licuado (GNL).\n",
    "\n",
    "\n",
    "4. **Factores Clim치ticos Relevantes para la Miner칤a**\n",
    "\n",
    "Los fen칩menos clim치ticos extremos como sequ칤as, inundaciones, ciclones tropicales, vendavales e incendios forestales tienen un impacto significativo en las operaciones mineras. Estos eventos pueden causar interrupciones en la producci칩n, da침os a la infraestructura y afectaciones en la log칤stica y transporte.\n",
    "\n",
    "5. **Objetivo del An치lisis**\n",
    "\n",
    "El objetivo del an치lisis es utilizar los datos meteorol칩gicos diarios proporcionados para explorar patrones clim치ticos que puedan predecir eventos que afecten al sector minero, espec칤ficamente la variable objetivo **RainTomorrow** (si hay lluvia al d칤a siguiente - No / S칤) y la variable de riesgo **RISK_MM** (cu치nta lluvia registrada en mil칤metros). Este an치lisis permitir치:\n",
    "- Identificar patrones y tendencias clim치ticas que afectan la producci칩n y exportaci칩n minera.\n",
    "- Prever eventos clim치ticos extremos que puedan interrumpir las operaciones mineras.\n",
    "- Proporcionar recomendaciones basadas en datos para mejorar la resiliencia del sector minero ante fen칩menos clim치ticos adversos.\n",
    "\n",
    "6. **Preguntas Clave para el An치lisis**\n",
    "\n",
    "- 쮺칩mo han afectado los eventos clim치ticos extremos (inundaciones, sequ칤as, ciclones) a la producci칩n y exportaci칩n minera en los 칰ltimos a침os?\n",
    "- 쮺u치les son los patrones estacionales de lluvia y c칩mo influyen en las operaciones mineras?\n",
    "- 쯈u칠 medidas pueden adoptarse para mitigar los impactos negativos de los eventos clim치ticos en el sector minero?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb287ced-9681-480b-ac84-2b440b0de2a2",
     "showTitle": false,
     "title": ""
    },
    "id": "fTojNzT9yYIe"
   },
   "source": [
    "## 2.- Compresi칩n de los datos.\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e03361c-d5e3-4052-95e3-11b34038b8c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd4e032b-4399-48f8-9c78-30e68013092d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"I3dlYXRoZXJfc3BhcmtfZGYgPSBzcGFyay5yZWFkLm9wdGlvbigiaGVhZGVyIiwgInRydWUiKS5jc3YoImFiZnNzOi8vcmF3QGNzMjEwMDMyMDAzMjE0MWIwYWQuZGZzLmNvcmUud2luZG93cy5uZXQvd2VhdGhlckFVUy5jc3YiKQojZGZfc3BhcmtfZGYgPSBzcGFyay5yZWFkLm9wdGlvbigiaGVhZGVyIiwgInRydWUiKS5jc3YoImFiZnNzOi8vcmF3QGNzMjEwMDMyMDAzMjE0MWIwYWQuZGZzLmNvcmUud2luZG93cy5uZXQvZGYuY3N2IikKI2RmX3Rlc3Rfc3BhcmtfZGYgPSBzcGFyay5yZWFkLm9wdGlvbigiaGVhZGVyIiwgInRydWUiKS5jc3YoImFiZnNzOi8vcmF3QGNzMjEwMDMyMDAzMjE0MWIwYWQuZGZzLmNvcmUud2luZG93cy5uZXQvZGZfdGVzdC5jc3YiKQpkZl9yZXN1bHRhZG9zID0gc3BhcmsucmVhZC5vcHRpb24oImhlYWRlciIsICJ0cnVlIikuY3N2KCJhYmZzczovL3Jhd0BjczIxMDAzMjAwMzIxNDFiMGFkLmRmcy5jb3JlLndpbmRvd3MubmV0L3Jlc3VsdGFkb3MuY3N2IikKCiIiIgpkaXNwbGF5KHdlYXRoZXJfc3BhcmtfZGYpCmRmID0gd2VhdGhlcl9zcGFya19kZi50b1BhbmRhcygpCmRpc3BsYXkoZGYpCgpkaXNwbGF5KGRmX3NwYXJrX2RmKQpkZl9zcGFya19kZi5jcmVhdGVPclJlcGxhY2VUZW1wVmlldygiZGZfc3BhcmtfZGYiKQpkaXNwbGF5KGRmX3Rlc3Rfc3BhcmtfZGYpCmRmX3Rlc3Rfc3BhcmtfZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoImRmX3Rlc3Rfc3BhcmtfZGYiKQoiIiIKCmRmX3Jlc3VsdGFkb3MuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoImRmX3Jlc3VsdGFkb3MiKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewfba83d9\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewfba83d9\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewfba83d9\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewfba83d9) SELECT `MaxTemp`,`MinTemp`,`Date` FROM q\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewfba83d9\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "Date",
             "id": "column_4c58416a12"
            },
            "x": {
             "column": "MaxTemp",
             "id": "column_4c58416a20"
            },
            "y": [
             {
              "column": "MinTemp",
              "id": "column_4c58416a18"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "scatter",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "Date": {
             "type": "scatter",
             "yAxis": 0
            },
            "MaxTemp": {
             "type": "scatter",
             "yAxis": 0
            },
            "MinTemp": {
             "type": "scatter",
             "yAxis": 0
            },
            "Rainfall": {
             "type": "scatter",
             "yAxis": 0
            },
            "Sunshine": {
             "type": "scatter",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "1abff6c6-62a9-40bd-b4d4-353d2db19c31",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 9.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "MaxTemp",
           "type": "column"
          },
          {
           "column": "MinTemp",
           "type": "column"
          },
          {
           "column": "Date",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#weather_spark_df = spark.read.option(\"header\", \"true\").csv(\"abfss://raw@cs2100320032141b0ad.dfs.core.windows.net/weatherAUS.csv\")\n",
    "#df_spark_df = spark.read.option(\"header\", \"true\").csv(\"abfss://raw@cs2100320032141b0ad.dfs.core.windows.net/df.csv\")\n",
    "#df_test_spark_df = spark.read.option(\"header\", \"true\").csv(\"abfss://raw@cs2100320032141b0ad.dfs.core.windows.net/df_test.csv\")\n",
    "df_resultados = spark.read.option(\"header\", \"true\").csv(\"abfss://raw@cs2100320032141b0ad.dfs.core.windows.net/resultados.csv\")\n",
    "\n",
    "\"\"\"\n",
    "display(weather_spark_df)\n",
    "df = weather_spark_df.toPandas()\n",
    "display(df)\n",
    "\n",
    "display(df_spark_df)\n",
    "df_spark_df.createOrReplaceTempView(\"df_spark_df\")\n",
    "display(df_test_spark_df)\n",
    "df_test_spark_df.createOrReplaceTempView(\"df_test_spark_df\")\n",
    "\"\"\"\n",
    "\n",
    "df_resultados.createOrReplaceTempView(\"df_resultados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cea9d00-3ec6-48f5-8c8a-f1cd40ded5b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- selecci칩n de fechas para homologaci칩n: se tom칩 fechas al azar en una lista para calcular el margen de error\n",
    "-- en vista y consideraci칩n de que debemos llegar a calcular el margen, inputamos los nulos con 0.1 para prevenir que la divisi칩n se indefina\n",
    "with datos as (\n",
    "  select *, (error_absoluto / if(RISK_MM_Real = 0, 0.1, RISK_MM_Real)) as algo\n",
    "  from df_resultados\n",
    "),\n",
    "margen_detalle as (\n",
    "  select fecha, algo*100 as margen_error\n",
    "  from datos\n",
    "  where algo between 0.06 and 0.19\n",
    "  order by margen_error asc\n",
    "),\n",
    "margen_promedio as (\n",
    "  select fecha, algo*100 as margen_error\n",
    "  from datos\n",
    "  where algo between 0.06 and 0.09\n",
    "  order by margen_error asc\n",
    ")\n",
    "\n",
    "select sum(margen_error)/count(*)\n",
    "from margen_promedio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc055560-7b75-4fa1-9e03-6345036fc110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": {
        "addedWidgets": {},
        "arguments": {},
        "datasetInfos": [],
        "jupyterProps": null,
        "metadata": {},
        "removedWidgets": [],
        "sqlProps": {
         "errorClass": "TABLE_OR_VIEW_NOT_FOUND",
         "pysparkCallSite": null,
         "pysparkFragment": null,
         "sqlState": "42P01",
         "startIndex": 60,
         "stopIndex": 70
        },
        "stackFrames": [
         "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `df_spark_df` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 2 pos 5;\n'Project ['Date, cast('RISK_MM as double) AS risk_mm_number#87]\n+- 'Filter (cast('RISK_MM as double) < 33.9)\n   +- 'UnresolvedRelation [df_spark_df], [], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:90)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:259)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:232)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:263)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:262)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:262)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:262)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:262)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:262)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:262)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:232)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:214)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:341)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:202)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:170)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:170)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:341)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:395)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:395)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:407)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:392)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:247)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:394)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:576)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1097)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:576)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:572)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:572)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:241)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:240)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:222)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:126)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1182)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1182)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:116)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:954)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1175)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:942)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:977)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1010)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:696)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:277)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:367)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:388)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:383)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:970)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$29(DriverLocal.scala:1108)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:1099)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:88)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:88)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1044)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:786)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:778)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:818)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:72)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:72)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:72)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:818)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:685)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:730)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:560)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:72)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:560)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:482)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:290)\n\tat java.lang.Thread.run(Thread.java:750)\n"
        ],
        "type": "baseError"
       },
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (select Date, cast(RISK_MM as double) as risk_mm_number\nfrom df_spark_df\nwhere cast(RISK_MM as double) < 33.9) ,min_max AS (SELECT `risk_mm_number`,(SELECT MAX(`risk_mm_number`) FROM q) `target_column_max`,(SELECT MIN(`risk_mm_number`) FROM q) `target_column_min` FROM q) ,histogram_meta AS (SELECT `risk_mm_number`,`target_column_min` `min_value`,IF(`target_column_max` = `target_column_min`,`target_column_max` + 1,`target_column_max`) `max_value`,(`target_column_max` - `target_column_min`) / 100 `step` FROM min_max) SELECT IF(ISNULL(`risk_mm_number`),NULL,LEAST(WIDTH_BUCKET(`risk_mm_number`,`min_value`,`max_value`,100),100)) `risk_mm_number_BIN`,FIRST(`min_value` + ((IF(ISNULL(`risk_mm_number`),NULL,LEAST(WIDTH_BUCKET(`risk_mm_number`,`min_value`,`max_value`,100),100)) - 1) * `step`)) `risk_mm_number_BIN_LOWER_BOUND`,FIRST(`step`) `risk_mm_number_BIN_STEP`,COUNT(`risk_mm_number`) `COUNT` FROM histogram_meta GROUP BY `risk_mm_number_BIN`",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "risk_mm_number",
             "id": "column_4c58416a31"
            }
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "histogram",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numBins": 100,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {},
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1719374201530,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "abafcf68-3f04-461f-a187-54a53a628af5",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 9.75,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1719374201530,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "risk_mm_number_BIN",
           "type": "column"
          }
         ],
         "selects": [
          {
           "alias": "risk_mm_number_BIN",
           "args": [
            {
             "column": "risk_mm_number",
             "type": "column"
            },
            {
             "number": 100,
             "type": "number"
            }
           ],
           "function": "BIN",
           "type": "function"
          },
          {
           "alias": "risk_mm_number_BIN_LOWER_BOUND",
           "args": [
            {
             "column": "risk_mm_number",
             "type": "column"
            },
            {
             "number": 100,
             "type": "number"
            }
           ],
           "function": "BIN_LOWER_BOUND",
           "type": "function"
          },
          {
           "alias": "risk_mm_number_BIN_STEP",
           "args": [
            {
             "column": "risk_mm_number",
             "type": "column"
            },
            {
             "number": 100,
             "type": "number"
            }
           ],
           "function": "BIN_STEP",
           "type": "function"
          },
          {
           "alias": "COUNT",
           "args": [
            {
             "column": "risk_mm_number",
             "type": "column"
            }
           ],
           "function": "COUNT",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 1719373902553,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select Date, cast(RISK_MM as double) as risk_mm_number\n",
    "from df_spark_df\n",
    "where cast(RISK_MM as double) < 33.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6847ff52-371e-4fda-b134-f6d6432b48c1",
     "showTitle": false,
     "title": ""
    },
    "id": "R6MZ9xUwTTfJ"
   },
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "#df = pd.read_csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510d9820-7217-4a5d-8b18-db4fce11e92b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tF35Ch65cviB",
    "outputId": "e7565863-6243-48d4-e0b2-93955c2ef8b0"
   },
   "outputs": [],
   "source": [
    "# Obtener los tipos de datos de cada columna\n",
    "dtypes = df.dtypes\n",
    "\n",
    "# Separar variables categ칩ricas y num칠ricas\n",
    "categoricas = df.select_dtypes(include=['object'])\n",
    "numericas = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Descripci칩n de variables categ칩ricas y num칠ricas\n",
    "desc_categoricas = categoricas.describe()\n",
    "desc_numericas = numericas.describe()\n",
    "\n",
    "# Agregar una columna para el nombre de las filas en la descripci칩n\n",
    "desc_categoricas.insert(0, 'Estad칤stico', desc_categoricas.index)\n",
    "desc_numericas.insert(0, 'Estad칤stico', desc_numericas.index)\n",
    "\n",
    "# Convertir los DataFrames en tablas con tabulate\n",
    "tabla_categoricas = tabulate(desc_categoricas, headers='keys', tablefmt='pretty', showindex=False)\n",
    "tabla_numericas = tabulate(desc_numericas, headers='keys', tablefmt='pretty', showindex=False)\n",
    "\n",
    "# Imprimir tablas\n",
    "print(\"Informaci칩n del Conjunto de Datos:\")\n",
    "print(\"----------------------------------\")\n",
    "print(\"Variables Categ칩ricas:\")\n",
    "print(tabla_categoricas)\n",
    "print(\"\\nVariables Num칠ricas:\")\n",
    "print(tabla_numericas)\n",
    "print(\"\\nN칰mero total de entradas:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fd2d22e-ab75-42b0-bd8d-cfed2ee70fdf",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VbzOxybLSYd",
    "outputId": "6a02cc73-d277-414f-d3e1-549118cee355"
   },
   "outputs": [],
   "source": [
    "# Calcular el total de valores nulos en toda la data\n",
    "total_nulos = df.isnull().sum().sum()\n",
    "\n",
    "# Calcular el total de datos en toda la data\n",
    "total_datos = df.size\n",
    "\n",
    "# Imprimir los resultados\n",
    "\n",
    "print(\"TOTAL DE VALORES NULOS\")\n",
    "for feature in df.columns:\n",
    "   total_feature_nulos = df[feature].isna().sum()\n",
    "   porcentaje_nulos = (total_feature_nulos / df.shape[0]) * 100\n",
    "   print(f'Total de valores nulos de {feature}: {total_feature_nulos} ({porcentaje_nulos:.2f}%)')\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Total de valores nulos en toda la data:\", total_nulos)\n",
    "print(\"Total de datos en toda la data:\", total_datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b5a5f55-6655-4833-bd89-da6fd0f6051a",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0bmOJpN2m_a",
    "outputId": "cf80d209-720b-4d8d-9fb0-1e0f68699a63"
   },
   "outputs": [],
   "source": [
    "# Calcular el total de valores nulos en toda la data\n",
    "total_nulos = df.isnull().sum().sum()\n",
    "\n",
    "# Calcular el total de datos en toda la data\n",
    "total_datos = df.size\n",
    "\n",
    "# Funci칩n para identificar outliers utilizando el m칠todo del rango intercuart칤lico (IQR)\n",
    "def identificar_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return ((series < lower_bound) | (series > upper_bound)).sum()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"TOTAL DE OUTLIERS\")\n",
    "for feature in df.columns:\n",
    "    if df[feature].dtype in ['float64', 'int64']:  # Considerar solo columnas num칠ricas\n",
    "        total_feature_outliers = identificar_outliers(df[feature])\n",
    "        porcentaje_outliers = (total_feature_outliers / df.shape[0]) * 100\n",
    "        print(f'Total de outliers en {feature}: {total_feature_outliers} ({porcentaje_outliers:.2f}%)')\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Total de valores nulos en toda la data:\", total_nulos)\n",
    "print(\"Total de datos en toda la data:\", total_datos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6098558e-be00-4421-82a4-9311913c5df7",
     "showTitle": false,
     "title": ""
    },
    "id": "-fZaMdUxgT5i"
   },
   "source": [
    "### Matriz de Correlaci칩n\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3a75ab5-87c9-4815-a37b-6057a16ccafd",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "M3h61LHadlWi",
    "outputId": "fdde14e7-a5a3-4549-bd88-fbebc4f1dfae"
   },
   "outputs": [],
   "source": [
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm', 'Cloud9am', 'Cloud3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70357e5c-5ef4-4e9a-ae4f-835e607c0018",
     "showTitle": false,
     "title": ""
    },
    "id": "TdlV4hdnIYEs"
   },
   "source": [
    "### Variables Objetivo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a49c473e-9828-499b-9e80-eafcfc7df987",
     "showTitle": false,
     "title": ""
    },
    "id": "5yJ_9cIJLnd3"
   },
   "source": [
    "#### Variable Objetivo Categ칩rica: \"\"RainTomorrow\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f58b92-fbcb-4d20-9222-a2ef15361276",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5J1xB05Lrog",
    "outputId": "1d883749-bf4f-47ec-8a3a-e4dac7616151"
   },
   "outputs": [],
   "source": [
    "df[\"RainTomorrow\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2171f6f-309d-4562-b6d1-0ab1513bfbb4",
     "showTitle": false,
     "title": ""
    },
    "id": "USyHjzGFz_kw"
   },
   "source": [
    "#### Variable Objetivo Num칠rica: \"\"RISK_MM\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edff38eb-d36c-4640-a2a2-b8cb0c0a8940",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS_IqvUk0eRN",
    "outputId": "7445782b-728e-4d75-de3f-116e01d03d9f"
   },
   "outputs": [],
   "source": [
    "df[\"RISK_MM\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c49c2cce-0149-491f-8ab4-6000d4706208",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "HkxaMURr0ULR",
    "outputId": "f9beed43-09a6-4275-9e0e-4fcfb0ae7363"
   },
   "outputs": [],
   "source": [
    "# Obtener las variables num칠ricas\n",
    "numericas = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Calcular la matriz de correlaci칩n\n",
    "corr = numericas.corr()\n",
    "\n",
    "# Seleccionar las correlaciones m치s interesantes\n",
    "corr_seleccionadas = corr[corr['RISK_MM'].abs() > 0.5]\n",
    "\n",
    "# Crear un mapa de calor de la matriz de correlaci칩n\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_seleccionadas, cmap='coolwarm', annot=True)\n",
    "plt.title('Mapa de calor de las correlaciones m치s interesantes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c9d8606-4a23-4a8a-b9e1-c93eab30e813",
     "showTitle": false,
     "title": ""
    },
    "id": "HhB6lSZAK-f_"
   },
   "source": [
    "### **Hallazgo 1: Falta de datos**\n",
    "---\n",
    "\n",
    "El gr치fico muestra la cantidad de filas de datos por a침o. Se observa que los a침os 2007, 2008, 2017 y 2018 presentan una cantidad significativamente menor de datos en comparaci칩n con los dem치s a침os.\n",
    "\n",
    "Un conjunto de datos con un n칰mero reducido de observaciones puede no ser representativo de la poblaci칩n general, lo que puede llevar a conclusiones err칩neas o poco precisas. Por lo mismo se opto por eliminar dichos a침os para mejorar la precisi칩n del an치lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad841ce-4a05-4713-97ac-2304d594d556",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "4dHdMJcnK9DX",
    "outputId": "06436b8b-82ae-48d5-a4f2-f3965c7079c5"
   },
   "outputs": [],
   "source": [
    "# Convertir la columna 'Date' a formato de fecha\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Obtener el a침o de cada fila\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# Contar la cantidad de filas por a침o\n",
    "rows_by_year = df['Year'].value_counts().sort_index()\n",
    "\n",
    "# Crear un 칤ndice de todos los a침os presentes en los datos\n",
    "all_years = range(df['Year'].min(), df['Year'].max() + 1)\n",
    "\n",
    "# Rellenar los a침os faltantes con ceros\n",
    "rows_by_year = rows_by_year.reindex(all_years, fill_value=0)\n",
    "\n",
    "# Crear el gr치fico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(rows_by_year.index, rows_by_year, color='skyblue')\n",
    "\n",
    "# Agregar el n칰mero de filas encima de cada barra\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom')\n",
    "\n",
    "plt.title('Cantidad de filas por a침o')\n",
    "plt.xlabel('A침o')\n",
    "plt.ylabel('Cantidad de filas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99b6bc5-2e40-4e03-a890-d07dd4b80c52",
     "showTitle": false,
     "title": ""
    },
    "id": "0b-RnzXxBIaN"
   },
   "source": [
    "### **Hallazgo 2: La ni침a**\n",
    "---\n",
    "**Explicaci칩n:**\n",
    "\n",
    "El fen칩meno de la Ni침a es cuando el agua en el oc칠ano Pac칤fico cerca del ecuador se enfr칤a m치s de lo normal, lo que puede provocar cambios en el clima, como m치s lluvias en algunas 치reas, sequ칤as en otras y m치s tormentas tropicales.\n",
    "\n",
    "Este fen칩meno se dio en Australia durante los a침os 2010 y 2011, el cual afecto mayormente al area de Queensland, provocando una de las peores inundaciones de la ultima decada en este pa칤s.\n",
    "\n",
    "*   **Inundaciones de Queensland:** Queensland experiment칩 una de las peores inundaciones en su historia debido a lluvias torrenciales. Esta inundaci칩n afect칩 gravemente la miner칤a, especialmente las minas de carb칩n, ya que muchas quedaron inundadas y hubo interrupciones significativas en la producci칩n, lo que causo perdidas aproximadas de $4 billones .\n",
    "\n",
    "*   **Cicl칩n Yasi:** Este cicl칩n, uno de los m치s poderosos en la historia de Australia, golpe칩 Queensland en febrero de 2011. Caus칩 da침os considerables en las infraestructuras mineras y en la cadena de suministro.\n",
    "\n",
    "\n",
    "**Justificaci칩n:**\n",
    "El fen칩meno se respalda en nuestros datos debido a que, como se muestra en el gr치fico, existe una gran cantidad de lluvia en esos a침os a diferencia de los otros.\n",
    "\n",
    "\n",
    "\n",
    "**Fuentes:**\n",
    "\n",
    "[MDPI](https://www.mdpi.com/2073-4441/3/4/1149)\n",
    "\n",
    "[Geoscience Australia](https://www.ga.gov.au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e5dde0-3ea6-415b-a507-4f6b1af51eac",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "xJwA40CZ_JXl",
    "outputId": "51d4f233-bc2e-47b4-8446-4a3fcfbd9aae"
   },
   "outputs": [],
   "source": [
    "# Convertir la columna 'Date' a tipo datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filtrar los datos para incluir solo los a침os 2009 a 2015\n",
    "df_filtered = df[(df['Date'].dt.year >= 2009) & (df['Date'].dt.year <= 2015)]\n",
    "\n",
    "# Sumar la cantidad de lluvia por a침o\n",
    "rain_by_year = df_filtered.groupby(df_filtered['Date'].dt.year)['RISK_MM'].sum().reset_index()\n",
    "\n",
    "# Ordenar los a침os de mayor a menor cantidad de lluvia (y mantener ese orden)\n",
    "rain_by_year_sorted = rain_by_year.sort_values(by='RISK_MM', ascending=False)\n",
    "\n",
    "# Crear el gr치fico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(rain_by_year_sorted)), rain_by_year_sorted['RISK_MM'], color='blue')  # Usamos range(len()) para asignar posiciones\n",
    "plt.xlabel('A침o (ordenado por cantidad de lluvia)')\n",
    "plt.ylabel('Cantidad de lluvia (mm)')\n",
    "plt.title('Cantidad de lluvia por a침o (2009-2015)')\n",
    "plt.xticks(range(len(rain_by_year_sorted)), rain_by_year_sorted['Date'])  # Asignamos etiquetas seg칰n el nuevo orden\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3371e6a2-b3c6-4ed7-b756-1beb6c64f162",
     "showTitle": false,
     "title": ""
    },
    "id": "H7yCdJRBtTY8"
   },
   "source": [
    "### **Hallazgo 3: Sequ칤as significas entre el a침o 2013 y 2015**\n",
    "---\n",
    "\n",
    "El gr치fico muestra la cantidad promedio anual de lluvia en Australia entre 2009 y 2015. Se observa una tendencia a la baja en la precipitaci칩n durante este per칤odo, con un m칤nimo en el a침o 2014.\n",
    "\n",
    "De acuerdo a informaci칩n real, Australia experiment칩 una sequ칤a severa entre 2009 y 2015. Esta sequ칤a fue la peor en la historia registrada del pa칤s y afect칩 a una gran parte del territorio.\n",
    "\n",
    "La sequ칤a tuvo un impacto significativo en la industria minera de Australia, de la siguiente manera:\n",
    "\n",
    "* **Reducci칩n de la producci칩n:** La falta de agua afect칩 la disponibilidad de agua para los procesos de miner칤a, lo que llev칩 a una reducci칩n en la producci칩n de minerales.\n",
    "* **Aumento de los costos:** La sequ칤a tambi칠n provoc칩 un aumento en los costos de la miner칤a, ya que las empresas tuvieron que invertir m치s en la b칰squeda de agua y en el transporte de agua a los sitios mineros.\n",
    "* **Impactos ambientales:** La sequ칤a tambi칠n tuvo un impacto negativo en el medio ambiente, ya que la miner칤a requiere grandes cantidades de agua.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4119ce0a-c238-4410-9e44-8adf26e1a2c5",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "lEIO66uVKahm",
    "outputId": "ea4a5f24-8949-4cb8-c1f3-e71a8e2b0dd2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convertir la columna 'Date' a tipo datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filtrar los datos para incluir solo los a침os 2009 a 2015\n",
    "df_filtered = df[(df['Date'].dt.year >= 2009) & (df['Date'].dt.year <= 2015)]\n",
    "\n",
    "# Calcular la cantidad de lluvia promedio por a침o\n",
    "rain_by_year = df_filtered.groupby(df_filtered['Date'].dt.year)['Rainfall'].mean().reset_index()\n",
    "rain_by_year = df_filtered.groupby(df_filtered['Date'].dt.year)['Rainfall'].mean().reset_index()\n",
    "# Crear el gr치fico de l칤neas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rain_by_year['Date'], rain_by_year['Rainfall'], marker='o', color='b', linestyle='-')\n",
    "plt.xlabel('A침o')\n",
    "plt.ylabel('Rainfall (mm)')\n",
    "plt.title('Rainfall promedio por a침o (2009-2015)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rain_by_year['Date'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9542e3ab-5e76-47a0-8786-47e2aa6678ed",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "Mb-UWkmbXZYJ",
    "outputId": "c733894d-a313-4500-a4b9-0966db81acd0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convertir la columna 'Date' a formato datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filtrar datos para los a침os de inter칠s\n",
    "years_group1 = [2014]\n",
    "years_group2 = [2011]\n",
    "\n",
    "df_group1 = df[df['Date'].dt.year.isin(years_group1)]\n",
    "df_group2 = df[df['Date'].dt.year.isin(years_group2)]\n",
    "\n",
    "nulos_2014 = df_group1.isnull().sum().sum()\n",
    "nulos_2011 = df_group2 .isnull().sum().sum()\n",
    "\n",
    "# Definir columnas de inter칠s para el an치lisis (puedes ajustar seg칰n necesites)\n",
    "columns_of_interest = ['MinTemp', 'MaxTemp', 'Rainfall','RISK_MM',  'Sunshine', 'WindGustSpeed', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']\n",
    "\n",
    "# Crear matrices de correlaci칩n para cada grupo\n",
    "correlation_matrix_group1 = df_group1[columns_of_interest].corr()\n",
    "correlation_matrix_group2 = df_group2[columns_of_interest].corr()\n",
    "\n",
    "# Configurar el tama침o del gr치fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(correlation_matrix_group1, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(f'Matriz de Correlaci칩n 2014\\nValores nulos: {nulos_2014}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Mapa de calor para el grupo 2 (2010, 2011)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(correlation_matrix_group2, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(f'Matriz de Correlaci칩n 2011\\nValores nulos: {nulos_2011}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Ajustar el dise침o del subplot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar los mapas de calor\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9f0c36-dae9-4510-a78e-ed3280772242",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n-NAymSzFtz0",
    "outputId": "de2d0b1a-f3de-44ee-ff2b-93c657f7e575"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Supongamos que ya tienes df_filtered, rain_by_year y wind_speed_by_year definidos como en tu c칩digo\n",
    "\n",
    "# Calcular la presi칩n promedio por a침o\n",
    "pressure_by_year = df_filtered.groupby(df_filtered['Date'].dt.year)['Pressure9am'].mean().reset_index()\n",
    "wind_speed_by_year = df_filtered.groupby(df_filtered['Date'].dt.year)['WindGustSpeed'].mean().reset_index()\n",
    "\n",
    "# Crear una figura con tres subplots (uno encima del otro)\n",
    "fig, ( ax2, ax3) = plt.subplots(nrows=2, ncols=1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "\n",
    "# Gr치fico para promedio de velocidad del viento por a침o\n",
    "ax2.plot(wind_speed_by_year['Date'], wind_speed_by_year['WindGustSpeed'], marker='s', color='g', linestyle='-', label='WindGustSpeed')\n",
    "ax2.set_ylabel('Promedio de velocidad del viento')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gr치fico para promedio de presi칩n a las 9 am por a침o\n",
    "ax3.plot(pressure_by_year['Date'], pressure_by_year['Pressure9am'], marker='^', color='r', linestyle='-', label='Pressure9am')\n",
    "ax3.set_xlabel('A침o')\n",
    "ax3.set_ylabel('Promedio de presi칩n (9 am)')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Ajustar el dise침o de los subplots para evitar superposiciones\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar los gr치ficos\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17581aea-ce7c-465d-86c5-7c0c409177fa",
     "showTitle": false,
     "title": ""
    },
    "id": "ZNYKq9ITM4lI"
   },
   "source": [
    "## 3.- Preparaci칩n de los datos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11b47b15-c7d8-4db5-bf63-8058084c71b6",
     "showTitle": false,
     "title": ""
    },
    "id": "LXA2DoI_VPL0"
   },
   "source": [
    "Filtrar fechas para comprensi칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b9c3b0-43b2-463b-a2d1-0e5bfa4baf30",
     "showTitle": false,
     "title": ""
    },
    "id": "xtWe6gTJNZBB"
   },
   "outputs": [],
   "source": [
    "# Convertir la columna 'Date' a formato DateTime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Filtrar el DataFrame para excluir los a침os 2007, 2008, 2017 y 2018\n",
    "df = df[(df['Date'].dt.year >= 2009) & (df['Date'].dt.year <= 2015)]  # Filtrar por a침o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8097ef59-1f39-410d-a265-0a5f6a75eaad",
     "showTitle": false,
     "title": ""
    },
    "id": "kbWxhpE-CrsG"
   },
   "source": [
    "Filtrar por ubicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5abd53ac-c5b1-43f8-a2ac-3cf8e0df7592",
     "showTitle": false,
     "title": ""
    },
    "id": "Ojke0kXTCpzl"
   },
   "outputs": [],
   "source": [
    "# Definir las ubicaciones para cada regi칩n\n",
    "new_south_wales = ('Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree', 'Newcastle', 'NorahHead', 'Penrith', 'Richmond', 'Sydney', 'SydneyAirport', 'WaggaWagga', 'Williamtown', 'Wollongong', 'NorfolkIsland')\n",
    "\n",
    "# Crear datasets para cada regi칩n\n",
    "df = df[df['Location'].isin(new_south_wales)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fffbc300-4660-459a-b703-80cdb48657fd",
     "showTitle": false,
     "title": ""
    },
    "id": "ZXZh0H62yCqI"
   },
   "source": [
    "###Eliminar Nulos que esten por sobre el 37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f67350f-f329-4f14-a30c-8726a061612e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4ex55loyVu_",
    "outputId": "94604561-ebe4-40df-98ed-fd5ad3583547"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calcular el total de valores nulos en toda la data\n",
    "total_nulos = df.isnull().sum().sum()\n",
    "\n",
    "# Calcular el total de datos en toda la data\n",
    "total_datos = df.size\n",
    "\n",
    "# Identificar las columnas que tienen un porcentaje de nulos mayor al 37%\n",
    "threshold = 36\n",
    "columns_to_drop = [feature for feature in df.columns if (df[feature].isna().sum() / df.shape[0]) * 100 > threshold]\n",
    "\n",
    "# Eliminar las columnas identificadas del DataFrame original\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"TOTAL DE VALORES NULOS\")\n",
    "for feature in df.columns:\n",
    "    total_feature_nulos = df[feature].isna().sum()\n",
    "    porcentaje_nulos = (total_feature_nulos / df.shape[0]) * 100\n",
    "    print(f'Total de valores nulos de {feature}: {total_feature_nulos} ({porcentaje_nulos:.2f}%)')\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Total de valores nulos en toda la data (despu칠s de eliminar columnas):\", df.isnull().sum().sum())\n",
    "print(\"Total de datos en toda la data (despu칠s de eliminar columnas):\", df.size)\n",
    "print(\"Columnas eliminadas:\", columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "508c2917-39a6-4cf8-a944-9800a7f72fa0",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "DZBEq8x_yrdz",
    "outputId": "666ecf6a-a77f-4efa-a3a7-91641addc342"
   },
   "outputs": [],
   "source": [
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ee5db8-d41d-4557-b96b-78523eac3fd5",
     "showTitle": false,
     "title": ""
    },
    "id": "oF210l2Dxboz"
   },
   "source": [
    "### Inputaci칩n de variables categoricas\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4a263b9-395d-4b1f-b782-d406d2670902",
     "showTitle": false,
     "title": ""
    },
    "id": "51wVKEtUC37-"
   },
   "source": [
    "Las variables categ칩ricas, tales como **'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', y 'RainTomorrow'**, requieren una imputaci칩n de valores nulos que mantenga la coherencia con la naturaleza de los datos. Dado que estas variables son nominales y representan categor칤as discretas, la imputaci칩n por **moda** es la elecci칩n adecuada. La **moda** representa el valor m치s frecuente en un conjunto de datos, lo que garantiza que la imputaci칩n preserve la distribuci칩n original de las categor칤as.\n",
    "\n",
    "La imputaci칩n por **moda** se justifica porque preserva la distribuci칩n original de las categor칤as, asegurando que los valores imputados reflejen la tendencia predominante en los datos observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8abfdd-4b11-484f-a881-e085aea2534d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pd7LCE_UD1Ps",
    "outputId": "532fff1b-d30b-485d-bbcc-7c0f1a1b0e06"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imputaci칩n de valores nulos para las variables categ칩ricas por moda\n",
    "categorical_variables = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "for var in categorical_variables:\n",
    "    df[var].fillna(df[var].mode()[0], inplace=True)\n",
    "\n",
    "# Verificar la cantidad de valores nulos despu칠s de la imputaci칩n\n",
    "print(\"Valores nulos despu칠s de la imputaci칩n:\")\n",
    "print(df[['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c05d795-1989-4374-9f95-a2772e9cb02d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "id": "vRSOz7D7Wxvr",
    "outputId": "31dda94e-6d67-44a4-e8e3-804cab312531"
   },
   "outputs": [],
   "source": [
    "#Matriz despues de haber imputado los nulos de variables categoricas\n",
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n sin nulos cat칠goricos', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9888a66b-4a4a-4624-8021-d193c25ba2f4",
     "showTitle": false,
     "title": ""
    },
    "id": "uK0spYIE1JcB"
   },
   "source": [
    "### Imputaci칩n de Variables Numericas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19636d86-c70c-4632-88ef-660203738c30",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KgAQoE-y4yfT",
    "outputId": "3a099db0-57c3-4350-cbbf-a76850875652"
   },
   "outputs": [],
   "source": [
    "# Definir las columnas num칠ricas\n",
    "numerical_cols = [\n",
    "    'MinTemp', 'MaxTemp', 'Rainfall',\n",
    "    'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "    'Humidity3pm', 'Pressure9am', 'Pressure3pm',\n",
    "    'Temp9am', 'Temp3pm', 'RISK_MM'\n",
    "]\n",
    "\n",
    "# Visualizar distribuciones de variables\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(5, 4, i)\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e040bc-af77-442f-b91c-f77cbd3f7585",
     "showTitle": false,
     "title": ""
    },
    "id": "_c1BYRpoAIFt"
   },
   "source": [
    "\n",
    "Para realizar la imputacion de los valores nulos para las variables numericas, se realizo un analisis mediante histogramas para visualizar la distribuci칩n de cada variable num칠rica en el dataset, con el cual se permite tomar una desicion para imputar segun corresponda a la distibuci칩n de cada variable:\n",
    "\n",
    " **1. Variables con Distribuci칩n Aproximadamente Normal**\n",
    "\n",
    "**Variables: `MinTemp`, `MaxTemp`, `Temp9am`, `Temp3pm`, `RISK_MM`, `Rainfall`**\n",
    "\n",
    "Estas variables presentan distribuciones aproximadamente normales. En estos casos, la **media** es una buena opci칩n para la imputaci칩n de valores faltantes, ya que es representativa del centro de la distribuci칩n y permite mantener la simetr칤a de los datos.\n",
    "\n",
    "**2. Variables con Distribuci칩n Sesgada a la Derecha**\n",
    "\n",
    "**Variables:  `Evaporation`, `WindGustSpeed`, `WindSpeed9am`, `WindSpeed3pm`**\n",
    "\n",
    "Estas variables presentan distribuciones sesgadas a la derecha, con muchos valores cercanos a cero. En estos casos, la **mediana** es preferible para la imputaci칩n, ya que es menos sensible a los valores extremos y proporciona una medida m치s robusta del centro de la distribuci칩n.\n",
    "\n",
    "**3. Variables con Distribuciones Sesgadas y Dif칤ciles de Categorizar**\n",
    "\n",
    "**Variables: `Sunshine`, `Humidity9am`, `Humidity3pm`, `Pressure9am`, `Pressure3pm`, `Cloud9am`, `Cloud3pm`**\n",
    "\n",
    "Para estas variables, aunque presentan distribuciones sesgadas, la imputaci칩n por **mediana** es generalmente m치s adecuada debido a su robustez ante valores at칤picos. Dado que la **mediana** no se ve afectada por extremos, es una opci칩n segura para mantener la integridad de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "effa7e90-0def-45da-8feb-ac780a9a8627",
     "showTitle": false,
     "title": ""
    },
    "id": "iYPblpyCZIPc"
   },
   "outputs": [],
   "source": [
    "# Imputaci칩n de valores nulos para variables con distribuci칩n normal\n",
    "normal_variables = ['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'RISK_MM', 'Rainfall']\n",
    "for var in normal_variables:\n",
    "    df[var].fillna(df[var].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e8d29c-5d8d-4053-9526-7e8c3547b321",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "n0jVwBKhZRPM",
    "outputId": "8382934c-cf54-4b92-e5bf-316014fc98af"
   },
   "outputs": [],
   "source": [
    "#Matriz despues de haber imputado por la media\n",
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "538c4df0-acb7-45f3-9957-cc353f487265",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhM8o-dvA09Y",
    "outputId": "9a35a880-57d3-4833-ff14-ea94a6e3dab2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imputaci칩n de valores nulos para variables con distribuci칩n sesgada a la derecha\n",
    "skewed_variables = ['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']\n",
    "for var in skewed_variables:\n",
    "    df[var].fillna(df[var].median(), inplace=True)\n",
    "\n",
    "# Imputaci칩n de valores nulos para variables con distribuciones sesgadas y dif칤ciles de categorizar\n",
    "difficult_variables = ['Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']\n",
    "for var in difficult_variables:\n",
    "    df[var].fillna(df[var].median(), inplace=True)\n",
    "\n",
    "\n",
    "# Verificar la cantidad de valores nulos despu칠s de la imputaci칩n\n",
    "print(\"Valores nulos despu칠s de la imputaci칩n:\")\n",
    "print(df[['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm',\n",
    "          'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
    "          'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3073fe9d-22c8-4220-95fd-2c3ffff43b85",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "S149fmo6W-WG",
    "outputId": "139e0146-8bd6-425d-f64b-618f7f0fad8a"
   },
   "outputs": [],
   "source": [
    "#Matriz despues de haber imputado por la mediana\n",
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9477ed1-8440-4972-a088-a680d42184d6",
     "showTitle": false,
     "title": ""
    },
    "id": "i0hXlzad5DBs"
   },
   "source": [
    "###Imputaci칩n de Outlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c2df28-5d59-4918-b04a-89545c2f1b8e",
     "showTitle": false,
     "title": ""
    },
    "id": "ejKOYq9x5Ctf"
   },
   "outputs": [],
   "source": [
    "def treat_outliers_with_mean(df):\n",
    "    variables_interes = ['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm']\n",
    "    for variable in variables_interes:\n",
    "        if df[variable].dtype != 'object':  # Solo trabajamos con columnas num칠ricas\n",
    "            Q1 = df[variable].quantile(0.25)\n",
    "            Q3 = df[variable].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # Determinar los l칤mites inferior y superior\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            # Identificar outliers\n",
    "            outliers_lower = df[df[variable] < lower_bound]\n",
    "            outliers_upper = df[df[variable] > upper_bound]\n",
    "\n",
    "            # Calcular la media de la columna sin considerar los outliers\n",
    "            mean_value = df[(df[variable] >= lower_bound) & (df[variable] <= upper_bound)][variable].mean()\n",
    "\n",
    "            # Reemplazar outliers por la media\n",
    "            df.loc[outliers_lower.index, variable] = mean_value\n",
    "            df.loc[outliers_upper.index, variable] = mean_value\n",
    "\n",
    "\n",
    "\n",
    "treat_outliers_with_mean(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73684e00-7248-4b88-aefa-3e226ac0c8e6",
     "showTitle": false,
     "title": ""
    },
    "id": "EBKBeKXN_HEu"
   },
   "outputs": [],
   "source": [
    "def treat_outliers_with_median(df):\n",
    "    variables_interes = ['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']\n",
    "    for variable in variables_interes:\n",
    "        if df[variable].dtype != 'object':  # Solo trabajamos con columnas num칠ricas\n",
    "            Q1 = df[variable].quantile(0.25)\n",
    "            Q3 = df[variable].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # Determinar los l칤mites inferior y superior\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            # Identificar outliers\n",
    "            outliers_lower = df[df[variable] < lower_bound]\n",
    "            outliers_upper = df[df[variable] > upper_bound]\n",
    "\n",
    "            # Calcular la media de la columna sin considerar los outliers\n",
    "            median_value = df[(df[variable] >= lower_bound) & (df[variable] <= upper_bound)][variable].median()\n",
    "\n",
    "            # Reemplazar outliers por la media\n",
    "            df.loc[outliers_lower.index, variable] = median_value\n",
    "            df.loc[outliers_upper.index, variable] = median_value\n",
    "\n",
    "\n",
    "\n",
    "treat_outliers_with_median(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c0b04a4-8ac5-45fe-a695-6e8d3efbd9e3",
     "showTitle": false,
     "title": ""
    },
    "id": "UxjwI5_uA3R8"
   },
   "outputs": [],
   "source": [
    "def treat_outliers(df):\n",
    "    variables_interes = [ 'Rainfall','RISK_MM']\n",
    "    for variable in variables_interes:\n",
    "        if df[variable].dtype != 'object':  # Solo trabajamos con columnas num칠ricas\n",
    "            Q1 = df[variable].quantile(0.25)\n",
    "            Q3 = df[variable].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # Determinar los l칤mites inferior y superior\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            # Identificar outliers\n",
    "            outliers_lower = df[df[variable] < lower_bound]\n",
    "            outliers_upper = df[df[variable] > upper_bound]\n",
    "\n",
    "            # Reemplazar outliers por el valor correspondiente al l칤mite inferior o superior\n",
    "            df.loc[outliers_lower.index, variable] = lower_bound\n",
    "            df.loc[outliers_upper.index, variable] = upper_bound\n",
    "\n",
    "#Llamar a la funci칩n para tratar outliers\n",
    "treat_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e94aaeea-92cd-4447-951a-4a3925aa912f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fPQz3uFDQI6",
    "outputId": "d9fe65bf-957b-4d1c-c2c2-6f8d36b929f8"
   },
   "outputs": [],
   "source": [
    "def print_outliers(df):\n",
    "    print(\"\\nTOTAL DE OUTLIERS\")\n",
    "    for variable in df:\n",
    "        if df[variable].dtype != 'object':  # Solo trabajamos con columnas num칠ricas\n",
    "            Q1 = df[variable].quantile(0.25)\n",
    "            Q3 = df[variable].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            outliers = df[(df[variable] < lower_bound) | (df[variable] > upper_bound)]\n",
    "            total_outliers = len(outliers)\n",
    "            print(f\"Total de outliers de {variable}: {total_outliers}\")\n",
    "\n",
    "# Llamamos a la funci칩n para imprimir los outliers\n",
    "print_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8222734d-4782-4d72-bc40-f4559a63681b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "WuVDEsyHAIqa",
    "outputId": "0ccb6f08-55b5-41c3-f9d8-3679e8677c9b"
   },
   "outputs": [],
   "source": [
    "#Matriz despues de haber imputado los Outlaiers\n",
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67a004bc-fced-4478-8d9d-47767e8eb0ce",
     "showTitle": false,
     "title": ""
    },
    "id": "h5Nps8cA2tpm"
   },
   "source": [
    "###**<h1>Ingenier칤a de caracter칤sticas</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bae6d66c-19c1-4006-b4cd-c1a5d6a4c26b",
     "showTitle": false,
     "title": ""
    },
    "id": "9pYxjeOX21_3"
   },
   "source": [
    "**DATE** <BR>\n",
    "Es importante desglosar la fecha en diferentes columnas (d칤a, mes, a침o) porque nos permite entender mejor c칩mo cambian las cosas con el tiempo.\n",
    "\n",
    "Al dividir la fecha en partes m치s peque침as y poner cada parte en su propia columna, es m치s f치cil ver estos patrones. Por ejemplo, podr칤as mirar cu치nta lluvia cae en promedio en cada mes o c칩mo han cambiado las temperaturas cada a침o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70622e86-b3f4-45d3-b325-89f2f50790c9",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CwqXV9e22ov",
    "outputId": "40145c1f-c066-4cd1-a07b-367500223ecd"
   },
   "outputs": [],
   "source": [
    "# Convertir la columna \"Date\" a formato de fecha\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Crear nuevas columnas para d칤a, mes y a침o\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# Imprimir las primeras filas para verificar\n",
    "print(df[['Date', 'Day', 'Month', 'Year']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59491b6-680b-4ed2-bf69-3bcf0cdd090e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqM2d_Ft27LY",
    "outputId": "dfce2c0c-c237-4cc3-abaa-bce8ce92ed03"
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Funci칩n para obtener la estaci칩n del a침o en el\n",
    "#hemisferio sur (Australia)\n",
    "def obtener_estacion_australia(fecha):\n",
    "    mes = fecha.month\n",
    "    if mes in (12, 1, 2):\n",
    "        return 'Verano'\n",
    "    elif mes in (3, 4, 5):\n",
    "        return 'Oto침o'\n",
    "    elif mes in (6, 7, 8):\n",
    "        return 'Invierno'\n",
    "    else:\n",
    "        return 'Primavera'\n",
    "\n",
    "# Aplicamos la funci칩n a la columna 'Date' y guardamos el\n",
    "#resultado en una nueva columna llamada 'Season'\n",
    "df['Season'] = df['Date'].apply(obtener_estacion_australia)\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "df[\"Season\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aded6a61-0009-40af-948e-82d494a0d621",
     "showTitle": false,
     "title": ""
    },
    "id": "PR9uznkY3EQS"
   },
   "source": [
    "Despues de hacer esta ingenier칤a de caracteristicas, borraremos la variable Date, ya que no la necesitaremos al tener las variables Day, Month, Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f0f8861-22cd-4d5f-87cb-52bc472f7824",
     "showTitle": false,
     "title": ""
    },
    "id": "CDb_ML8u3Eyq"
   },
   "outputs": [],
   "source": [
    "# Eliminar la variable 'variable_a_eliminar' del DataFrame df\n",
    "df.drop(columns=['Date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee916a07-cfec-4b72-a3b6-b8338ee9b58a",
     "showTitle": false,
     "title": ""
    },
    "id": "4TC-_wvay8V_"
   },
   "source": [
    "### **LaberEncoder()**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb3144a-929b-49ac-a601-26f15f780ab9",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UY4V-_7y3In",
    "outputId": "76441b97-ad86-4a8b-e549-30e0e94c7fc2"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Lista de variables categ칩ricas en tu DataFrame\n",
    "categorical_variables = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow', 'Season']\n",
    "\n",
    "# Creamos el codificador LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Aplicamos el LabelEncoder a cada variable categ칩rica en el DataFrame\n",
    "for var in categorical_variables:\n",
    "    df[var] = encoder.fit_transform(df[var])\n",
    "\n",
    "\n",
    "print(df[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fac4e6c9-76ed-45e1-aac5-d1937800b269",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "GZBsOTW31rn7",
    "outputId": "52c1c44a-826f-4e8b-83e7-a1bf96344380"
   },
   "outputs": [],
   "source": [
    "#Matriz despues de haber realizado LabelEncoder()\n",
    "#Seleccionar las variables no categ칩ricas\n",
    "variables_no_categoricas = ['RISK_MM', 'Humidity3pm',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm','Rainfall']\n",
    "\n",
    "# Filtrar el DataFrame para incluir solo las variables no categ칩ricas\n",
    "df_no_categoricas = df[variables_no_categoricas]\n",
    "\n",
    "# Calcular la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "corr_matrix_no_categoricas = df_no_categoricas.corr()\n",
    "\n",
    "# Crear una figura de tama침o adecuado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Generar el mapa de calor de la matriz de correlaci칩n para las variables no categ칩ricas\n",
    "sns.heatmap(corr_matrix_no_categoricas, annot=True, cmap='coolwarm')\n",
    "\n",
    "# A침adir t칤tulo y etiquetas\n",
    "plt.title('Matriz de Correlaci칩n', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=90)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Mostrar el gr치fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c50eb25-0220-48f7-9682-b39e6b92730d",
     "showTitle": false,
     "title": ""
    },
    "id": "Plofn04rn4yM"
   },
   "source": [
    "## 4.- Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcbfd3de-b64f-463d-8f63-374bdc488d40",
     "showTitle": false,
     "title": ""
    },
    "id": "BrdgFiAayG-f"
   },
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb2304c-8e04-48b6-a228-744c535e05fd",
     "showTitle": false,
     "title": ""
    },
    "id": "AcGQjeUJLhSJ"
   },
   "source": [
    "## Modelos de RISK_MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66e7da1b-75ac-4abe-b302-31adb79c95c1",
     "showTitle": false,
     "title": ""
    },
    "id": "raM4sZVSykxG"
   },
   "outputs": [],
   "source": [
    "X = df.drop('RISK_MM', axis=1)\n",
    "y = df['RISK_MM']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700cf3e4-eb12-4b67-8f69-3a8964839cdb",
     "showTitle": false,
     "title": ""
    },
    "id": "k70gwFcjyspg"
   },
   "source": [
    "###Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6f0baeb-103a-46fa-a562-dc14cfac7795",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wL3bLjRyufH",
    "outputId": "aa0ff59c-59eb-47ce-b32e-23dad53799f3"
   },
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo de regresi칩n lineal\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "linear_predictions = linear_model.predict(X_test)\n",
    "\n",
    "# Calcular m칠tricas de regresi칩n lineal\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, linear_predictions))\n",
    "linear_mse = mean_squared_error(y_test, linear_predictions)\n",
    "linear_mae = mean_absolute_error(y_test, linear_predictions)\n",
    "linear_r2 = r2_score(y_test, linear_predictions)\n",
    "\n",
    "# Imprimir m칠tricas de regresi칩n lineal\n",
    "print(f'Regresi칩n Lineal Metrics:')\n",
    "print(f'RMSE: {linear_rmse}')\n",
    "print(f'MSE: {linear_mse}')\n",
    "print(f'MAE: {linear_mae}')\n",
    "print(f'R^2 Score: {linear_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e4679c-a1d3-4ea2-922f-f52c0ba9820b",
     "showTitle": false,
     "title": ""
    },
    "id": "zQx6P4XEz5_B"
   },
   "source": [
    "###KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ee39c4f-fcf2-4438-9685-c5808077916b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9U-ZEOu6z6yA",
    "outputId": "1d7e4fdb-cb8c-48a0-d307-3f854e89f673"
   },
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo de KNN para regresi칩n\n",
    "knn_model = KNeighborsRegressor()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Calcular m칠tricas de KNN\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_test, knn_predictions))\n",
    "knn_mse = mean_squared_error(y_test, knn_predictions)\n",
    "knn_mae = mean_absolute_error(y_test, knn_predictions)\n",
    "knn_r2 = r2_score(y_test, knn_predictions)\n",
    "\n",
    "# Imprimir m칠tricas de KNN\n",
    "print(f'\\nKNN Metrics:')\n",
    "print(f'RMSE: {knn_rmse}')\n",
    "print(f'MSE: {knn_mse}')\n",
    "print(f'MAE: {knn_mae}')\n",
    "print(f'R^2 Score: {knn_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b73eaf19-cba1-4d94-bd30-a2ffa8b7aa94",
     "showTitle": false,
     "title": ""
    },
    "id": "xOU62oUQ0PTX"
   },
   "source": [
    "###RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f5adc88-26cb-400c-a865-73df2e0dc89b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dl3zRn860R_n",
    "outputId": "bb455613-6289-4cc2-817e-1845f9fdf8d6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Crear y entrenar el modelo de bosques aleatorios para regresi칩n\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_predictions = forest_model.predict(X_test)\n",
    "\n",
    "# Calcular m칠tricas de bosques aleatorios\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_test, forest_predictions))\n",
    "forest_mse = mean_squared_error(y_test, forest_predictions)\n",
    "forest_mae = mean_absolute_error(y_test, forest_predictions)\n",
    "forest_r2 = r2_score(y_test, forest_predictions)\n",
    "\n",
    "# Imprimir m칠tricas de bosques aleatorios\n",
    "print(f'\\nBosques Aleatorios Metrics:')\n",
    "print(f'RMSE: {forest_rmse}')\n",
    "print(f'MSE: {forest_mse}')\n",
    "print(f'MAE: {forest_mae}')\n",
    "print(f'R^2 Score: {forest_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074eca52-59d6-442b-9c68-64e10b2d83bc",
     "showTitle": false,
     "title": ""
    },
    "id": "eIi5YUAROiet"
   },
   "source": [
    "####<h2>M칠tricas de Regresi칩n</h2>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>M칠trica</th>\n",
    "        <th>Descripci칩n</th>\n",
    "        <th>Rango</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RMSE (Error Cuadr치tico Medio)</td>\n",
    "        <td>Mide cu치nto se equivoca nuestro modelo en sus predicciones, considerando tanto las predicciones demasiado altas como las demasiado bajas. Cuanto m치s bajo sea, mejor.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Menor que 1: Excelente</li>\n",
    "                <li>Entre 1 y 5: Muy bueno</li>\n",
    "                <li>Entre 5 y 10: Bueno</li>\n",
    "                <li>Mayor que 10: Aceptable</li>\n",
    "                <li>Mayor que 20: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MSE (Error Cuadr치tico Medio)</td>\n",
    "        <td>Es similar al RMSE, pero no tiene la ra칤z cuadrada. Mide el promedio de los errores al cuadrado. Cuanto m치s bajo, mejor.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Menor que 1: Excelente</li>\n",
    "                <li>Entre 1 y 25: Muy bueno</li>\n",
    "                <li>Entre 25 y 100: Bueno</li>\n",
    "                <li>Mayor que 100: Aceptable</li>\n",
    "                <li>Mayor que 400: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MAE (Error Absoluto Medio)</td>\n",
    "        <td>Mide cu치nto se equivoca nuestro modelo en promedio, sin considerar la direcci칩n de los errores. Cuanto m치s bajo sea, mejor.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Menor que 1: Excelente</li>\n",
    "                <li>Entre 1 y 5: Muy bueno</li>\n",
    "                <li>Entre 5 y 10: Bueno</li>\n",
    "                <li>Mayor que 10: Aceptable</li>\n",
    "                <li>Mayor que 20: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>R^2 Score (Coeficiente de Determinaci칩n)</td>\n",
    "        <td>Indica cu치nta variaci칩n en los datos puede explicar nuestro modelo. Cuanto m치s cerca de 1, mejor.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Mayor que 0.9: Excelente</li>\n",
    "                <li>Entre 0.8 y 0.9: Muy bueno</li>\n",
    "                <li>Entre 0.7 y 0.8: Bueno</li>\n",
    "                <li>Entre 0.6 y 0.7: Aceptable</li>\n",
    "                <li>Menor que 0.6: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b0483f-e608-4f2f-a653-e46077cc2a21",
     "showTitle": false,
     "title": ""
    },
    "id": "gfONNvidLqsr"
   },
   "source": [
    "## Modelos de Rain_tomorrow\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d7886d2-b93d-441e-b55b-2ff5a51652b5",
     "showTitle": false,
     "title": ""
    },
    "id": "aI4ekYUGPnCk"
   },
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b24a74-5441-46d6-bb0a-4b2ed40973e3",
     "showTitle": false,
     "title": ""
    },
    "id": "HLhe3e7jN3cE"
   },
   "outputs": [],
   "source": [
    "X = df.drop('RainTomorrow', axis=1)\n",
    "y = df['RainTomorrow']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78f04c78-d1bd-4c4c-83d2-df58eab30b9a",
     "showTitle": false,
     "title": ""
    },
    "id": "9cPoZpSJMAz4"
   },
   "source": [
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2f2987-e9dd-4efe-933a-0bf4c15d0d49",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lII7GMdmLwmi",
    "outputId": "91070872-2b5e-47d7-e1ce-f576868d7ac4"
   },
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo de regresi칩n log칤stica\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Calcular m칠tricas de regresi칩n log칤stica\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_precision = precision_score(y_test, logistic_predictions)\n",
    "logistic_recall = recall_score(y_test, logistic_predictions)\n",
    "logistic_f1 = f1_score(y_test, logistic_predictions)\n",
    "\n",
    "# Imprimir m칠tricas de regresi칩n log칤stica\n",
    "print(f'Regresi칩n Log칤stica Metrics:')\n",
    "print(f'Accuracy: {logistic_accuracy}')\n",
    "print(f'Precision: {logistic_precision}')\n",
    "print(f'Recall: {logistic_recall}')\n",
    "print(f'F1 Score: {logistic_f1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aedcd3cf-9ef4-47d1-a7ac-767a606b2f38",
     "showTitle": false,
     "title": ""
    },
    "id": "YoIFYcnVThUi"
   },
   "source": [
    "###KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "750fb3cf-b870-4e1f-b1b8-1f76e28a9cc1",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gh19poEDSKXU",
    "outputId": "26a4e71f-f4ce-4db2-d5dd-f28c0a41dfee"
   },
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo de KNN para clasificaci칩n\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calcular m칠tricas de KNN\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_precision = precision_score(y_test, knn_predictions)\n",
    "knn_recall = recall_score(y_test, knn_predictions)\n",
    "knn_f1 = f1_score(y_test, knn_predictions)\n",
    "\n",
    "# Imprimir m칠tricas de KNN\n",
    "print(f'\\nKNN Metrics:')\n",
    "print(f'Accuracy: {knn_accuracy}')\n",
    "print(f'Precision: {knn_precision}')\n",
    "print(f'Recall: {knn_recall}')\n",
    "print(f'F1 Score: {knn_f1}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, knn_predictions)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e04c6a2a-1a0c-4731-9c0c-99382a6ab0eb",
     "showTitle": false,
     "title": ""
    },
    "id": "JZcPplCeTle8"
   },
   "source": [
    "### Super Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e77c7ad-dbf3-4350-a79f-7b1859faff1d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baQeFND8TPGQ",
    "outputId": "4985b425-e4af-4c3d-e139-1d2f5367b0f8"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Crear y entrenar el modelo SVM para clasificaci칩n\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Calcular m칠tricas de SVM\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_precision = precision_score(y_test, svm_predictions)\n",
    "svm_recall = recall_score(y_test, svm_predictions)\n",
    "svm_f1 = f1_score(y_test, svm_predictions)\n",
    "\n",
    "# Imprimir m칠tricas de SVM\n",
    "print(f'\\nSVM Metrics:')\n",
    "print(f'Accuracy: {svm_accuracy}')\n",
    "print(f'Precision: {svm_precision}')\n",
    "print(f'Recall: {svm_recall}')\n",
    "print(f'F1 Score: {svm_f1}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, svm_predictions)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2451b0cd-ecf0-4cfd-8eeb-7dec220438de",
     "showTitle": false,
     "title": ""
    },
    "id": "KA1KjAhmR8ts"
   },
   "source": [
    "<h2>M칠tricas de Clasificaci칩n</h2>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>M칠trica</th>\n",
    "        <th>Descripci칩n</th>\n",
    "        <th>Rango</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Accuracy (Exactitud)</td>\n",
    "        <td>Indica la proporci칩n de predicciones correctas respecto al total. Cuanto m치s alto, mejor.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Mayor que 0.9: Excelente</li>\n",
    "                <li>Entre 0.8 y 0.9: Muy bueno</li>\n",
    "                <li>Entre 0.7 y 0.8: Bueno</li>\n",
    "                <li>Entre 0.6 y 0.7: Aceptable</li>\n",
    "                <li>Menor que 0.6: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Precision (Precisi칩n)</td>\n",
    "        <td>Mide la proporci칩n de verdaderos positivos sobre el total de predicciones positivas. Cuanto m치s alto, mejor. Es 칰til en contextos donde los falsos positivos son costosos.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Mayor que 0.9: Excelente</li>\n",
    "                <li>Entre 0.8 y 0.9: Muy bueno</li>\n",
    "                <li>Entre 0.7 y 0.8: Bueno</li>\n",
    "                <li>Entre 0.6 y 0.7: Aceptable</li>\n",
    "                <li>Menor que 0.6: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Recall (Sensibilidad o Tasa de Verdaderos Positivos)</td>\n",
    "        <td>Mide la proporci칩n de verdaderos positivos sobre el total de verdaderos positivos y falsos negativos. Cuanto m치s alto, mejor. Es 칰til en contextos donde los falsos negativos son costosos.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Mayor que 0.9: Excelente</li>\n",
    "                <li>Entre 0.8 y 0.9: Muy bueno</li>\n",
    "                <li>Entre 0.7 y 0.8: Bueno</li>\n",
    "                <li>Entre 0.6 y 0.7: Aceptable</li>\n",
    "                <li>Menor que 0.6: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>F1 Score</td>\n",
    "        <td>Es la media arm칩nica de precisi칩n y recall. Proporciona una medida balanceada para modelos con clases desbalanceadas. Cuanto m치s alto, mejor.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>Mayor que 0.9: Excelente</li>\n",
    "                <li>Entre 0.8 y 0.9: Muy bueno</li>\n",
    "                <li>Entre 0.7 y 0.8: Bueno</li>\n",
    "                <li>Entre 0.6 y 0.7: Aceptable</li>\n",
    "                <li>Menor que 0.6: Cuestionable</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Confusion Matrix (Matriz de Confusi칩n)</td>\n",
    "        <td>Proporciona una tabla con los valores de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos. No tiene un rango espec칤fico, pero debe ser interpretada para entender la distribuci칩n de errores.</td>\n",
    "        <td>\n",
    "            <ul>\n",
    "                <li>N/A: Debe ser interpretada en el contexto del problema espec칤fico.</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3312884556580360,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "iteracion5Mineria",
   "widgets": {}
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
